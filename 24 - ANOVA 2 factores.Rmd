---
title: "24 - ANOVA 2 factores y m谩s"
output: html_notebook
---

Una descripci贸n completa que puede encontrar on line.

-   Joaqu铆n Amat Rodrigo (2016). ANOVA an谩lisis de varianza para comparar m煤ltiples medias.
<https://cienciadedatos.net/documentos/19_anova>

```{r}
library(tidyverse)
library(emmeans)
library(car)
```

# ANOVA para dos factores

Para realizar un ANOVA usamos la funci贸n aov(), que tiene como primer par谩metro el modelo lineal que deseamos evaluar. El modelo lineal gen茅rico es:

$$
Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha * \beta)_{ij} + \epsilon_{ijk}
$$

Donde:

-   Y es la variable respuesta.
-    es la media de todos los datos juntos
-    es el efecto de grupo i茅simo del factor .
-    es el efecto de grupo j茅simo del factor .
-   *es el efecto de interacci贸n entre ambos factores.
-    es el residual del individuo k茅simo perteneciente al i茅simo grupo del factor  y el j茅simo grupo del factor . 
Se asume que los residuales tienen distribuci贸n normal con media 0 y varianza sigma cuadrado:

$$
\epsilon_{ijk} \sim N(0, \sigma^2)
$$

La hip贸tesis a probar en un ANOVA de dos factores son varias. Se prueba:

-   el modelo globalmente (es decir que ninguno de los grupos difiere del resto)
-   cada factor por separado (los grupos dentro de un factor no difieren entre s铆)
-   cada una de las interacciones (es decir los grupos de un factor dentro de cada grupo del otro factor no difieren entre s铆)

## Un ejemplo: ToothGrowth

### Primero "miramos los datos"

#### Graficamos

```{r}
ggplot(ToothGrowth, aes(x = factor(dose), y = len, colour = supp)) + 
    geom_boxplot() +
    geom_jitter(width = .1) +
  ggtitle("ToothGrowth")
```

```{r}
ggplot(ToothGrowth, aes(y = len, x = factor(dose), color = supp)) +
  geom_jitter(width = 0.1) +
  stat_summary(fun = mean, geom = "point", shape = 3, size = 8, stroke = 2, show.legend = FALSE, alpha = 0.5) +
  labs(title = "Medias de ToothGrowth por Dosis y Suplemento",
       x = "Dosis",
       y = "Longitud de los Dientes")
```

##### Calculamos los 铆ndices

```{r}
tgc <- ToothGrowth %>% group_by(supp, dose) %>% reframe(n = n(), media = mean(len), sd = sd(len), se = sd / sqrt(n), ci = 1.96*se) # aqu铆 se usa una versi贸n del intervalo de confianza ci que es muuuy simplificada (como se ver谩 m谩s adelante).
# tgc$supp <- as.factor(tgc$supp)
# tgc$dose <- as.factor(tgc$dose)
tgc
```

```{r}
ggplot(tgc, aes(x = dose, y = media, colour = supp)) + 
    geom_errorbar(aes(ymin = media-ci, ymax = media+ci), width = .1) +
    geom_line() +
    geom_point() +
  labs(title = "ANOVA ToothGrowth",
       subtitle = "Crecimiento de dientes y vitamina C",
       caption = "Las barras de error representan el Intervalo de Confianza al 95%")
```

## Hacemos el ANOVA

### Con aov()

```{r}
anovaModel <- aov(len ~ supp + factor(dose) + supp:factor(dose), data = ToothGrowth)
# anovaModel <- aov(len ~ supp * factor(dose), data = ToothGrowth)
summary(anovaModel)

emmeans(anovaModel, ~ supp * factor(dose))
```

```{r}
anovaModel$coefficients
```

### Con lm()

Tambi茅n puede realizarse con la funci贸n lm(), que se refiere a modelos lineales (Linear Model). En t茅rminos estrictos lm() y glm(), no realizan un ANOVA s铆no m谩s bien una Regresi贸n Lineal (que veremos en la pr贸xima clase). Lo que ocurre es que cuando una Regrasi贸n Lineal tiene variables explicatorias categ贸ricas en vez de cont铆nuas, el an谩lisis de Regrasi贸n Lineal es igual a una ANOVA.

Aqu铆 se puede ver en la 煤ltima l铆nea que el estad铆stico de prueba, los grados de libertad y el p-value coinciden con el resultado de aov(), ya que est谩n calculados para el modelo completo. Adem谩s se puede ver que los coeficientes son los mismos. 

El R虏 es el coeficiente de correlaci贸n (no el de Pearson, porque la variable explicatoria es categ贸rica). lm() es m谩s correcto usarlo para regresi贸n lineal, es decir cuando la variable explicatoria es num茅rica (el tema se abordar谩 m谩s adelante).

```{r}
lmModel <- lm(len ~ supp * factor(dose), data = ToothGrowth)
summary(lmModel)
```

### Con glm()

La funci贸n glm() Se refiere a modelos lineales generalizados (Generalized Linear Models). Hace lo mismo (en este caso), pero tiene otras alternativas.

-   lm() (Linear Model): Se utiliza para ajustar modelos de regresi贸n lineal. La relaci贸n entre la variable dependiente Y y las variables independientes X se asume lineal, y la variable dependiente debe ser continua. Los errores deben ser normalmente distribuidos y tener varianza constante (homocedasticidad).

-   glm() (Generalized Linear Model): Es una generalizaci贸n de lm() y permite ajustar modelos lineales generalizados. Esto incluye modelos donde la variable dependiente puede seguir una distribuci贸n diferente a la Normal, como Binomial, Poisson, Gamma, entre otras. Se especifica una funci贸n de enlace para conectar la media de la variable dependiente con las variables predictoras. Por ejemplo, la regresi贸n log铆stica (para variables binarias) o la regresi贸n de Poisson (para datos de conteo) se ajustan con glm().

```{r}
# Realizar un modelo GLM
glmModel <- glm(len ~ supp * factor(dose), data = ToothGrowth)

# Mostrar un resumen del modelo GLM
summary(glmModel)

# Calcular efectos por grupo
efectosPorGrupo <- emmeans(glmModel, ~ supp * dose)

# Mostrar los efectos por grupo
summary(efectosPorGrupo, infer = c(TRUE, TRUE), level = 0.95)
```

## Verificaci贸n de supuestos

### Normalidad

```{r}
shapiro.test(residuals(anovaModel))
```

### Homogeneidad de varianzas

Se presentan 3 alternativas:

```{r}
bartlett.test(len ~ interaction(supp, dose), data = ToothGrowth)
```

```{r}
fligner.test(len ~ interaction(supp, dose), data = ToothGrowth)
```

```{r}
# library(car)
leveneTest(len ~ supp * factor(dose), data = ToothGrowth)
```

La formula del modelo puede escribirse as铆 tambi茅n:

```{r}
# library(car)
leveneTest(len ~ interaction(supp, dose), data = ToothGrowth)
```

### Autocorrelaci贸n de residuos

Este test (Durbin-Watson) es importante cuando hay muchas variables explicatorias, verifica que nos est茅n correlacionadas entre s铆. En este caso que hay s贸lo dos variables explicatorias es muy improbable que haya autocorrelaci贸n y por lo tanto generalmente no hace falta hacer la verificaci贸n. La incluyo aqu铆 de todas maneras para mostrar c贸mo se raliza.

```{r}
# library(car)
dwt(anovaModel)
```


### Supuestos Gr谩ficamente

```{r}
par(mfrow = c(2,2))
plot(anovaModel, pch = 16)
```


# Comparaciones m煤ltiples (Post Hoc)

El siguiente v铆nculo aborda este tema m谩s extensamente.

Joaqu铆n Amat Rodrigo (2016). "Comparaciones m煤ltiples: correcci贸n de p-value y FDR".
<https://rpubs.com/Joaquin_AR/236898>

Las funciones LSD.test() y pairwise.t.test() puede usar los siguientes m茅todos: "holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr", "none" (T de Student)

## Intervalos LSD de Fisher (Least Significance Difference)

```{r}
library(agricolae)
lsdTest <- LSD.test(anovaModel, c("supp", "factor(dose)"), p.adj="bonferroni", alpha = 0.01, group=FALSE)
lsdTest
```

## Tukey-Kramer (HSD). Honest Significant Difference. Tambi茅n conocido como correcci贸n de Dunnet.

```{r}
tukeyTest <- TukeyHSD(anovaModel)
tukeyTest
```

```{r}
plot(tukeyTest)
```


## Aqu铆 una soluci贸n de chatgpt.

Me gusta porque es muy sint茅tica y completa.

```{r}
library(lmtest)
# Cargar el dataset y convertir 'dose' a factor
data("ToothGrowth")
ToothGrowth$dose <- as.factor(ToothGrowth$dose)

# ANOVA de dos factores con interacci贸n
modelo_toothgrowth <- aov(len ~ supp * dose, data = ToothGrowth)

# Resumen del ANOVA
summary(modelo_toothgrowth)

# Verificaci贸n de normalidad
qqnorm(resid(modelo_toothgrowth))
qqline(resid(modelo_toothgrowth))
shapiro.test(resid(modelo_toothgrowth))

# Verificaci贸n de homogeneidad de varianzas
plot(fitted(modelo_toothgrowth), resid(modelo_toothgrowth))
leveneTest(len ~ supp * dose, data = ToothGrowth)
bartlett.test(len ~ interaction(supp, dose), data = ToothGrowth)

# Verificaci贸n de independencia (si es necesario)
dwtest(modelo_toothgrowth)
```


