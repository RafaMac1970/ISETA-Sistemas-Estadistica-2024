---
title: "20 - Test de HipÃ³tesis"
output: 
  html_notebook: 
    toc: true
---

## Referencias recomendadas:

Para un texto mÃ¡s detallado que este mire:

-   Prueba de HipÃ³tesis EstadÃ­stica: una explicaciÃ³n desde cero. PROBA FÃCIL (2018).
<https://probafacil.com/prueba-de-hipotesis-estadistica>. 

Es una explicaciÃ³n simple, sin detalles matemÃ¡ticos que cubre todo lo necesario para nuestros objetivos. 

Para una explicaciÃ³n mÃ¡s rigurosa y detallada recomiendo (no estÃ¡ en lÃ­nea):

-   Batista William (2020). IntroducciÃ³n a la inferencia estadÃ­stica aplicada. 2da Ed. Editorial Facultad de AgronomÃ­a. 272 pgs. <https://www.agro.uba.ar/catalog/introducci-n-la-inferencia-estad-stica-aplicada-3ra-edici-n>

# IntroducciÃ³n

El mÃ©todo cientÃ­fico parte de una pregunta que sugiere hipÃ³tesis cientÃ­ficas de las que se derivan predicciones (cuando se realiza un experimento). Las predicciones implican recopilar datos y plantear hipÃ³tesis estadÃ­sticas sobre los mismos. El rechazo de las hipÃ³tesis estadÃ­sticas permiten deducir algo acerca de la pregunta original.

Una hipÃ³tesis cientÃ­fica es por lo tanto un postulado categÃ³rico que puede refutarse (falsacionismo de Karl Popper) y busca entender las causas de los fenÃ³menos observados. Las hipÃ³tesis estadÃ­sticas son similares salvo por que no hablan sobre las causas, se refieren Ãºnicamente a las asociaciones entre variables, la interpretaciÃ³n de las asociaciones es potestad del cientÃ­fico.

La refutaciÃ³n de una hiopÃ³tesis cuando hay incertidumbre se puede hacer de modo probabilÃ­stico, es decir que siempre habrÃ¡ cierta probabilidad de error. Por lo tanto lo que debemos hacer es controlar el error. Por un lado debemos decidir quÃ© error es razonable asumir y por otro debemos medir la probabilidad de error al tomar una decisiÃ³n. Ambos asuntos tienen su dificultad y particularidades. Por ahora nos centraremos en el cÃ¡lculo de la probabilidad de error.

Al poner a prueba una hipÃ³tesis hay siempre dos tipos de error que podemos cometer, por un lado rechazar una hipÃ³tesis verdadera (Error de tipo I) y por otro aceptar una hipÃ³tesis falsa (Error de tipo II). El siguiente cuadro resume la situaciÃ³n.

|                    |                     |                       |
|:------------------:|:-------------------:|:---------------------:|
|                    |    **H0 Verdadera** |      **H0 Falsa**     |
|  **Rechazar H0**   | Error de tipo I (âº) |    Correcto (1-ğ›½)    |
| **No Rechazar H0** |   Correcto (1-âº)    | Error de tipo II (ğ›½) |

âº: es la magnitud del error de tipo I que estamos dispuestos a aceptar
ğ›½: es la magnitud del error de tipo II que estamos dispuestos a aceptar

âº y ğ›½ los fijamos antes de poner a prueba las hipÃ³tesis. Esto depende de nuestro conocimiento acerca del fenÃ³meno investigado (conocimiento disciplinar) y de la evaluaciÃ³n del riesgo que hagamos (aquÃ­ la estadÃ­stica tambiÃ©n tiene herramientas para asistirnos). MÃ¡s adelante discutiremos esta decisiÃ³n mÃ¡s en profundidad. 

# Tipos de pruebas de hipÃ³tesis

Existen muchas pruebas de hipÃ³tesis posibles. Las mÃ¡s importantes (porque cubren la mayorÃ­a de los casos) se resument en el siguiente cuadro.

|                              |                |                        |                       |               |
|:-----------------------------|:---------------|:----------------------:|:---------------------:|:-------------:|
|                              |                |**Unilateral Izquierda**|**Unilateral Derecha** |**Bilateral**  |
|  **Una media poblacional**   |                |  H0) ğ â‰¥ ğ0          |  H0) ğ â‰¤ ğ0         |  H0) ğ = ğ0 |
| **Dos medias poblacionales** | apareadas      |  H0) ğ1 â‰¥ ğ2         |  H0) ğ1 â‰¤ ğ2        |  H0) ğ1 = ğ2|
| **Dos medias poblacionales** | independientes |  H0) ğ1 â‰¥ ğ2         |  H0) ğ1 â‰¤ ğ2        |  H0) ğ1 = ğ2|

Cada hipÃ³tesis nula (H0) de la tabla tiene una H1 alternativa que hace a las dos hipÃ³tesis exhaustivas, es decir que cubren todos los resultados posibles.

Todas estas hipÃ³tesis se prueban en principio con una distribuciÃ³n T de Student. Existen otras posibles distribuciones para casos particulares. Existen ademÃ¡s otras pruebas posibles, por ejemplo para probar diferencias en proporciones, o testear normalidad en una distribuciÃ³n, o si una correlaciÃ³n es significativa, etc.. En general son adaptaciones de estas mismas pruebas. Veremos algunas de ellas mÃ¡s adelante.

Lo que cambia en cada caso es el estadÃ­stico de prueba, es decir el valor que comparo con la distribuciÃ³n de probabilidad (en este caso T de Student). Esto es lo que me permite calcular el la probabilidad de error (valor-p).

## EstadÃ­sticos de prueba.

La siguiente tabla es un resumen acerca de los tipos bÃ¡sicos de pruebas de hipÃ³tesis. Con esta tabla podrÃ¡ realizar la mayorÃ­a de las pruebas de hipÃ³tesis para variables cuantitativas. FuÃ© tomada de: <https://maniqui-es.com/educacin-y-lenguas/matemticas/estadsticas/18655-manejo-de-pruebas-de-hiptesis-estadsticas.html>

NÃ³tese que no diferencia entre poblaciÃ³n y muestra, sÃ³lo muestra el aspecto matemÃ¡tico de la diferencia indicando el desvÃ­o estandar como sigma o S. Las pruebas sobre la poblaciÃ³n usan una distribuciÃ³n Z, que es la Normal estandarizada. En cambio las pruebas sobre la muestra usan una distribuciÃ³n T de Student.

![](images/handling-statistical-hypothesis-tests_1.jpg)

# Pasos para realizar las pruebas de HipÃ³tesis

1.  Formular dos hipÃ³tesis estadÃ­sticas. (la nula H0 y la alternativa H1)
2.  Elegir el mÃ¡ximo riesgo de rechazar equivocadamente la hipÃ³tesis nula (H0). (âº, lÃ­mite para el error de tipo I)
3.  Generar los datos necesarios.
4.  Evaluar el grado de concordancia entre los datos y H0 (valor-p).
5.  Compara el valor-p con âº y decidir si se rechaza o no H0.
6.  Si No rechazamos H0 debemos evaluar la probabilidad de cometer error de tipo II (a este asunto le dedicaremos otro notebook). 

# Diferencia estadÃ­sticamente significativa.

Se usan las expresiones "diferencia significativa" y "diferencia no significativa". 

Existe diferrencia estadÃ­sticamente significativa cuando rechazamos la hipÃ³tesis nula, es decir que el "valor-p" es menor a "âº". Esto significa que cometemos un error menor al aceptable al decir que NO es cierto que las medias comparadas son iguales (H0), y por lo tanto aceptamos la hipÃ³tesis alternativa (H1), que dice que las medias son diferentes entre sÃ­.

Cuando el "valor-p" es mayor a "âº", decimos que las diferencias medidas son "no significativas" (no decimos que no existen, para esto deberÃ­amos evaluar el error de tipo II). Es decir que las diferencias no son suficientemente grandes como para asegurar con baja probabilidad de equivocarnos que los datos obtenidos son diferentes entre las dos poblaciones de referencia.

# AnÃ¡lisis de casos concretos.

## MediciÃ³n de reflejos

Vamos a utilizar los datos procesados del notebook "05 - Ejercicios - Tendencia central y varianza - Reflejos.Rmd". En el notebook original hay una descripciÃ³n del experimento.

```{r}
library(tidyverse)
library(BSDA)
# library(nortest)
# library(ggplot2)
# library(moments)
```

```{r}
reflejosTidy <- read_csv("datos/reflejos_tidy.csv")
```

Vamos a excluir algunos outliers que distorsionan los datos. Los detalles acerca de las razones para la exclusiÃ³n mÃ­relas en el notebook original.

```{r}
reflejosTidy <- reflejosTidy %>% filter(DISTANCIA < 30) %>% filter(NOMBRE != "MARIO")
head(reflejosTidy)
```

### Muestreo

AdemÃ¡s vamos a submuestrear las mediciones originales para observar el efecto del tamaÃ±o de las muestras (cantidad de repeticiones) sobre el valor-p (p-value). Esto es suponer que hubieramos tomado menos repeticiones, por eso seleccionamos con el nÃºmero de orden. Primero observe los resultados con todas las repeticiones y luego descomente la lÃ­nea siquiente y ejecute el notebook nuevamente para comparar los resultados.

```{r}
# reflejosTidy <- reflejosTidy %>% filter(ORDEN <= 10)
```

### ComparaciÃ³n de una muestra con un valor de referencia. (Una media poblacional, unilateral izquierda)

Suele considerarse que el tiempo de reacciÃ³n media de una persona normal (al realizar una tarea simple) que estÃ¡ atenta al estÃ­mulo varÃ­a alrrededor de 0.22 segundos. Este valor puede variar de acuerdo a las circunstancias (depende cÃ³mo se lo mida, si la persona estÃ¡ entrenada -como los deportistas-, quÃ© estÃ­mulo desencadena la respuesta, quÃ© respuesta se considera, la complejidad de la decisiÃ³n,etc.). Queremos verificar si las personas que hicieron el experimento tienen reflejos mÃ¡s rÃ¡pidos al promedio poblacional. Para este caso vamos a usar 0.22 segundos como valor de referecia.

Por lo tanto nuestras hipÃ³tesis serÃ­an:

$$
H_{0}: \mu \geq 0.22 \\
H_{1}: \mu < 0.22
$$

### Primero un BoxPlot

```{r}
mu <- 0.22 # es el valor de referencia en nuestras hipÃ³tesis
```

```{r}
ggplot(reflejosTidy) +
  aes(x = NOMBRE, y = TIEMPO) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5, color = "blue") +
  ylim(c(0, 0.25)) +
  geom_hline(yintercept = mu)
```

#### Suponiendo que conocemos la varianza de la poblaciÃ³n.

Primero vamos a calcular los parÃ¡metros necesarios. Como lo que necesitaremos es el desvÃ­o estÃ¡ndar lo calcularemos en lugar de la varianza.

La varianza de la poblaciÃ³n la calcularemos como la varianza de las mediciones de las 3 personas medidas. (es una suposiciÃ³n que no debe estar muy alejada de la realidad, pero deberÃ­amos ser cuidadosos con esa suposiciÃ³n).

```{r}
desvioEstandarPoblacion <- sd(reflejosTidy$TIEMPO)
desvioEstandarPoblacion
```

AdemÃ¡s elegiremos como un error mÃ¡ximo aceptable el 5%, es decir que alfa = 0.05. Esto quiere decir que si aceptamos H0, lo hacemos con el 95% de confianza.

Probaremos las hipÃ³tesis para cada persona por separado.

```{r}
persona <- "RAFA" # "RAFA" "NACHO" "LAUTA"
muestraUnaPersona <- reflejosTidy %>% filter(NOMBRE == persona) 
```

Usamos una distribuciÃ³n Normal Estandarizada. El estadÃ­stico de prueba es:

$$
\frac{\bar{x} - \mu_0}{\frac{\sigma}{\sqrt{n}} } 
$$

```{r}
media0 <- mean(muestraUnaPersona$TIEMPO)
n <- nrow(muestraUnaPersona)

estadisticoDePrueba <- (media0- mu) / (desvioEstandarPoblacion / sqrt(n))

media0
n
estadisticoDePrueba

pnorm(estadisticoDePrueba, mean = 0, sd = 1, lower.tail = TRUE) # Usamos mean = 0 y sd = 1 porque es una DistribuciÃ³n Normal Estandarizada
```

Todo ese procedimiento anterior lo realiza directamente sobre la muestra el z.test(). Si no especificamos sigma.x lo calcula en base a la muestra, en nuestro caso lo calculamos en base a los datos de las 3 personas, por eso debemos indicarselo. (el z.test() no estÃ¡ en R-base, por eso cargamos al inicio el paquete BSDA)

```{r}
zTestPersona <- z.test(muestraUnaPersona$TIEMPO, alternative='less', mu = mu, sigma.x = desvioEstandarPoblacion) # la H1 dice que la media real es menor a mu, eso se especifica con "less". PodrÃ­a ser tambiÃ©n "two.sided" o "greater" 
zTestPersona
```

```{r}
errorEstandarPoblacion <- desvioEstandarPoblacion / sqrt(n)
rango = c(min(mu - 3 * errorEstandarPoblacion, media0), mu + 3 * errorEstandarPoblacion)
ggplot(data.frame(x = rango), aes(x = rango)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mu, sd = errorEstandarPoblacion)) +
  geom_area(stat = 'function', fun = dnorm, args = list(mean = mu, sd = errorEstandarPoblacion), fill = '#ff0018', xlim = c(rango[1], media0), alpha = 0.5) +
  geom_vline(xintercept = mu) +
  geom_label(aes(x = media0, y = -7, label = round(media0,3)))  +
  ylab("Densidad") + ggtitle("DistribuciÃ³n Normal") + xlab("tiempo de respuesta (seg)")
```

```{r}
rango = c(min(-3,zTestPersona$statistic-1), 3)
ggplot(data.frame(x = rango), aes(x = rango)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1)) +
  geom_area(stat = 'function', fun = dnorm, args = list(mean = 0, sd = 1), fill = '#ff0018', xlim = c(rango[1],zTestPersona$statistic), alpha = 0.5) + 
  geom_vline(xintercept = zTestPersona$statistic) +
  geom_label(aes(x = zTestPersona$statistic, y = -0.02, label = round(zTestPersona$statistic,3))) +
  geom_label(aes(x = zTestPersona$statistic, y = 0.1, label = zTestPersona$p.value)) +
  ylab("Densidad") + ggtitle("DistribuciÃ³n Normal EstÃ¡ndar") + xlab("tiempo Normalizado")
```

#### Suponiendo que NO conocemos la varianza de la poblaciÃ³n.

Probaremos las hipÃ³tesis para cada persona por separado.

Usamos una distribuciÃ³n T de Student. El estadÃ­stico de prueba es:

$$
\frac{\bar{x} - \mu_0}{\frac{s}{\sqrt{n}} } 
$$

```{r}
media0<- mean(muestraUnaPersona$TIEMPO)
desvioEstandarMuestra <- sd(muestraUnaPersona$TIEMPO)
n <- nrow(muestraUnaPersona)

estadisticoDePrueba <- (media0- mu) / (desvioEstandarMuestra / sqrt(n))

media0
desvioEstandarMuestra
n
estadisticoDePrueba
pt(estadisticoDePrueba, df = n - 1, lower.tail = TRUE)
```

Todo ese procedimiento anterior lo realiza directamente sobre la muestra el t.test()

```{r}
tTestPersona <- t.test(muestraUnaPersona$TIEMPO, alternative = "less", mu = mu) # la H1 dice que la media real es menor a mu, eso se especifica con "less". PodrÃ­a ser tambiÃ©n "two.sided" o "greater"
tTestPersona
```

```{r}
rango = c(min(-3,tTestPersona$statistic-1), 3)
ggplot(data.frame(x = rango), aes(x = rango)) +
  stat_function(fun = dt, args = list(df = tTestPersona$parameter)) +
  geom_area(stat = 'function', fun = dt,  args = list(df = tTestPersona$parameter), fill = '#ff0018', xlim = c(rango[1],tTestPersona$statistic), alpha = 0.5) + 
  geom_vline(xintercept = tTestPersona$statistic) +
  geom_label(aes(x = tTestPersona$statistic, y = -0.02, label = round(tTestPersona$statistic,3))) +
  geom_label(aes(x = tTestPersona$statistic, y = 0.1, label = tTestPersona$p.value))  +
  ylab("Densidad") + ggtitle("DistribuciÃ³n T de Student") + xlab("tiempo Normalizado")
```

InterpretaciÃ³n: (para el caso de RAFA y con la muestra completa - n = 29-) como el valor-p (0.003941) es menor a 0.05 rechazamos H0 y por lo tanto concluÃ­mos que el tiempo de respuesta de "RAFA" es menor al 0.22 que es el promedio poblacional supuesto (H1 es verdadera).

### ComparaciÃ³n de dos muestras. (Dos medias poblacionales independientes, bilateral)

AquÃ­ vamos a comparar los tiempos de reacciÃ³n de dos personas. Como a priori no tengo ninguna razÃ³n para suponer que una de las personas tiene menor tiempo de respuesta que otra, las hipÃ³tesis se plantean como igual o distinto.

En este caso las muestras NO son apareadas ya que cada mediciÃ³n es independiente.

$$
H_{0}: \mu_A = \mu_B \\
H_{1}: \mu_A \neq \mu_B
$$ 

Que es lo mismo que decir:

$$
H_{0}: \mu_A - \mu_B = 0\\
H_{1}: \mu_A - \mu_B \neq 0
$$

Este segundo par de hipÃ³tesis es lo que en realidad pone a prueba el test T (lea atentamente la salida del mÃ©todo t.test() "alternative hypothesis: true difference in means is not equal to 0").

El estadÃ­stico de prueba para muestras independientes es:

$$
\frac{\bar{x}_1 - \bar{x}_2}{ s_a \cdot \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
$$

donde SÂ²a es la varianza amalgamada, que es muy parecida a una varianza promedio.

$$
S^2_a = \frac{(n_1 - 1) \cdot S^2_1 + (n_2 - 1) \cdot S^2_2}{ n_1 + n_2 - 2}
$$

```{r}
 # "RAFA" "NACHO" "LAUTA"
p1 <- "NACHO"
p2 <- "RAFA"
muestraP1 <- reflejosTidy %>% filter(NOMBRE == p1)
nP1 <- nrow(muestraP1)
mediaP1 <- mean(muestraP1$TIEMPO)
varP1 <- var(muestraP1$TIEMPO)
# eeP1 <- sqrt(varP1) / sqrt(nP1)
eeP1 <- sd(muestraP1$TIEMPO) / sqrt(nP1)

muestraP2 <- reflejosTidy %>% filter(NOMBRE == p2)
nP2 <- nrow(muestraP2)
mediaP2 <- mean(muestraP2$TIEMPO)
varP2 <- var(muestraP2$TIEMPO)
# eeP2 <- sqrt(varP2) / sqrt(nP2)
eeP2 <- sd(muestraP2$TIEMPO) / sqrt(nP2)

s2A <- ((varP1 * (nP1 - 1)) + (varP2 * (nP2 - 1))) / (nP1 + nP2 - 2) # varianza amalgamada, es parecida al promedio de las dos varianzas
estadisticoDePrueba <- (mediaP1 - mediaP2) / (sqrt(s2A) * sqrt((1 / nP1) + (1 / nP1))) 
estadisticoDePrueba

2 * pt(estadisticoDePrueba, df = (nP1 + nP2 - 2), lower.tail = TRUE)
```

```{r}
rango = c(min(mediaP1 - 3 * eeP1, mediaP2 - 3 * eeP2), max(mediaP1 + 3 * eeP1, mediaP2 + 3 * eeP2))

ggplot(data.frame(x = rango), aes(x = rango)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = mediaP1, sd = eeP1), color = "blue") +
  stat_function(fun = dnorm, n = 101, args = list(mean = mediaP2, sd = eeP2), color = "darkgreen") +
  geom_vline(xintercept = mediaP1, color = "blue") +
  geom_vline(xintercept = mediaP2, color = "darkgreen") +
  geom_label(aes(x = mediaP1, y = -0.02, label = round(mediaP1,3))) +
  geom_label(aes(x = mediaP2, y = -0.02, label = round(mediaP2,3))) +
  geom_label(aes(x = mediaP1, y = 150, label = p1)) +
  geom_label(aes(x = mediaP2, y = 150, label = p2)) +
  ylab("Densidad") + ggtitle("DistribuciÃ³n Normal") + xlab("Tiempo de Respuesta (seg)")
```

```{r}
tTestDiferencia <- t.test(muestraP1$TIEMPO, muestraP2$TIEMPO, alternative = "two.sided", paired = FALSE) #  "less" "two.sided" "greater" AdemÃ¡s puede agregar la opciÃ³n , var.equal = TRUE 
tTestDiferencia
```

NÃ³tese que este mÃ©todo realizÃ³ el test de Welch en vez del de Student, las diferencias son leves y se deben a un leve ajuste que hace cuando calcula el estadÃ­stico de Prueba y los grados de libertad. Este ajuste depende de las diferencias entre las varianzas de las dos muestras. Cuando las varianzas son iguales, los dos test dan el mismo resultado. Puede verificar esto al comparar RAFA con LAUTA (varianzas diferentes) o RAFA con NACHO (varianzas parecidas).


```{r}
rango = c(min(-3,tTestDiferencia$statistic-1), 3)

ggplot(data.frame(x = rango), aes(x = rango)) +
  stat_function(fun = dt, args = list(df = tTestDiferencia$parameter)) +
  geom_area(stat = 'function', fun = dt, args = list(df = tTestDiferencia$parameter), fill = '#ff0018', xlim = c(rango[1],tTestDiferencia$statistic), alpha = 0.5) + 
  geom_vline(xintercept = tTestDiferencia$statistic) +
  geom_label(aes(x = tTestDiferencia$statistic, y = -0.02, label = round(tTestDiferencia$statistic,3))) +
  geom_label(aes(x = tTestDiferencia$statistic, y = 0.1, label = tTestDiferencia$p.value))  +
  ylab("Densidad") + ggtitle("DistribuciÃ³n T de Student") + xlab("Diferencia de tiempo Normalizado")
```
